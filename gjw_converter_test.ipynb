{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening datastore /Users/GJWood/nilm_gjw_data\\HDF5\\nilm_gjw_data.hdf5\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\hooks\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\info\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\heads\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\remotes\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\remotes\\origin\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\03\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\07\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\08\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\0d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\16\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\1f\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\25\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\3b\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\46\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\48\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\4a\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5b\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5c\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\65\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\6d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\6e\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\70\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\71\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\73\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\76\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\79\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\7d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\7e\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\88\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\89\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\8f\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\97\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\99\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\a0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\a5\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\ae\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\b2\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\b9\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\bd\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\c0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\c4\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\ca\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\cb\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\cd\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\d9\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e5\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e6\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\eb\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f4\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f6\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f7\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\info\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\pack\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\heads\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\remotes\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\remotes\\origin\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\tags\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\\.ipynb_checkpoints\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\\building1\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\\building1\\elec\n",
      "found files for date: 2013-11-20\n",
      "found files for date: 2013-11-28\n",
      "found files for date: 2013-12-01\n",
      "found files for date: 2013-12-04\n",
      "found files for date: 2013-12-13\n",
      "found files for date: 2013-12-27\n",
      "found files for date: 2014-01-09\n",
      "found files for date: 2014-02-09\n",
      "found files for date: 2014-03-27\n",
      "found files for date: 2014-05-26\n",
      "found files for date: 2015-05-12\n",
      "found files for date: 2015-05-27\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'instance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7ec4615ba3d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[0mconvert_gjw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c:/Users/GJWood/nilm_gjw_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-7ec4615ba3d9>\u001b[0m in \u001b[0;36mconvert_gjw\u001b[1;34m(gjw_path, output_filename, format)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mbreak\u001b[0m \u001b[1;31m# only 1 folder with .csv files at present\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mconvert_yaml_to_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgjw_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done converting gjw to HDF5!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjwood\\nilm_metadata\\nilm_metadata\\convert_yaml_to_hdf5.pyc\u001b[0m in \u001b[0;36mconvert_yaml_to_hdf5\u001b[1;34m(yaml_dir, hdf_filename)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0m_set_data_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melec_meters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0m_sanity_check_meters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melec_meters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeter_devices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0m_sanity_check_appliances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuilding_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_f_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuilding_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjwood\\nilm_metadata\\nilm_metadata\\convert_yaml_to_hdf5.pyc\u001b[0m in \u001b[0;36m_sanity_check_appliances\u001b[1;34m(building_metadata)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mappl_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappliance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0minstances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappliance_instances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0minstances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappliance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mappliance_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mappliance_instances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'instance'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from os.path import join, isdir, isfile\n",
    "from os import listdir\n",
    "import fnmatch\n",
    "import re\n",
    "from sys import stdout\n",
    "from nilmtk.utils import get_datastore\n",
    "from nilmtk.datastore import Key\n",
    "from nilmtk.timeframe import TimeFrame\n",
    "from nilmtk.measurement import LEVEL_NAMES\n",
    "from nilmtk.utils import get_module_directory, check_directory_exists\n",
    "from nilm_metadata import convert_yaml_to_hdf5, save_yaml_to_datastore\n",
    "\n",
    "column_mapping = {\n",
    "    'active': ('power', 'active'),\n",
    "    'reactive': ('power', 'reactive')\n",
    "    \n",
    "}\n",
    "# data for file name manipulation\n",
    "filename_prefix_mapping = {\n",
    "    'active' : ('4-POWER_REAL_FINE '),\n",
    "    'reactive' : ('5-POWER_REACTIVE_STANDARD ')\n",
    "}\n",
    "filename_suffix_mapping = {\n",
    "    'active' : (' Dump'),\n",
    "    'reactive' : (' Dump')\n",
    "}\n",
    "# DataFrame column names\n",
    "TIMESTAMP_COLUMN_NAME = \"timestamp\"\n",
    "ACTIVE_COLUMN_NAME = \"active\"\n",
    "REACTIVE_COLUMN_NAME = \"reactive\"\n",
    "\n",
    "TIMEZONE = \"Europe/London\" # local time zone\n",
    "home_dir='/Users/GJWood/nilm_gjw_data' # path to input data\n",
    "\n",
    "#regular expression matching\n",
    "bld_re = re.compile('building\\d+') #used to pull building name from directory path\n",
    "bld_nbr_re = re.compile ('\\d+') # used to pull the building number from the name\n",
    "iso_date_re = re.compile ('\\d{4}-\\d{2}-\\d{2}') # used to pull the date from the file name\n",
    "\n",
    "def convert_gjw(gjw_path, output_filename, format=\"HDF\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    gjw_path : str\n",
    "        The root path of the gjw dataset.\n",
    "    output_filename : str\n",
    "        The destination filename (including path and suffix), will default if not specified\n",
    "    directory and file structure\n",
    "    nilm_gjw_data\n",
    "        building<1>\n",
    "            elec\n",
    "                4-POWER_REAL_FINE <date> Dump.csv\n",
    "                5-POWER_REACTIVE_STANDARD <date> Dump.csv\n",
    "                ...\n",
    "        ...\n",
    "        building<n>\n",
    "        HDF5\n",
    "            nilm_gjw_data.hdf5\n",
    "        metadata\n",
    "            building1.yaml\n",
    "            dataset.yaml\n",
    "            meter_devices.yaml\n",
    "        other files    \n",
    "    \"\"\"\n",
    "    if gjw_path is None: gjwpath = home_dir\n",
    "    check_directory_exists(gjw_path)\n",
    "    os.chdir(gjw_path)\n",
    "    gjw_path = os.getcwd()  # sort out potential issue with slashes or backslashes\n",
    "    if output_filename is None:\n",
    "        output_filename =join(home_dir,'HDF5','nilm_gjw_data.hdf5')\n",
    "    elec_path = join(gjw_path, 'building1','elec')\n",
    "    # Open data store\n",
    "    print( 'opening datastore', output_filename)\n",
    "    store = get_datastore(output_filename, format, mode='w')\n",
    "    # walk the directory tree from the dataset home directory\n",
    "    # process any .CSV files found\n",
    "    df = pd.DataFrame(columns=[TIMESTAMP_COLUMN_NAME,ACTIVE_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "    found = False\n",
    "    for current_dir, dirs_in_current_dir, files in os.walk(gjw_path):\n",
    "        if current_dir.find('.git')!=-1:\n",
    "            print( 'Skipping ', current_dir)\n",
    "            continue\n",
    "        print( 'checking', current_dir)\n",
    "        m = bld_re.search(current_dir)\n",
    "        if m:\n",
    "            building_name = m.group()\n",
    "            building_number = int(bld_nbr_re.search(building_name).group())\n",
    "            meter_nbr = 1\n",
    "            key = Key(building=building_number, meter=meter_nbr)\n",
    "        #clear dataframe df\n",
    "        #add column headers\n",
    "        for items in fnmatch.filter(files, \"4*.csv\"):\n",
    "            found = True\n",
    "            ds = iso_date_re.search(items).group()\n",
    "            print( 'found files for date:', ds)\n",
    "            # found files to process\n",
    "            df1,df2 = _read_filename_pair(current_dir,ds) # read the csv files into dataframes\n",
    "            df3 = pd.merge(df1,df2,on=TIMESTAMP_COLUMN_NAME) #merge the two column types into 1 frame \n",
    "            df = pd.concat([df,df3]) # concatenate the results into one long dataframe\n",
    "        if found:\n",
    "            found = False\n",
    "            df = _tidy_data(df)\n",
    "            csvout = join(current_dir,'meter'+str(meter_nbr)+'.data') # not called .csv to avoid clash\n",
    "            #print( csvout)\n",
    "            df.to_csv(csvout)\n",
    "            store.put(str(key), df)\n",
    "            #df = pd.DataFrame(columns=[TIMESTAMP_COLUMN_NAME,ACTIVE_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "            break # only 1 folder with .csv files at present\n",
    "    store.close()\n",
    "    convert_yaml_to_hdf5(join(gjw_path, 'metadata'),output_filename)\n",
    "    print(\"Done converting gjw to HDF5!\")\n",
    "\n",
    "def _read_filename_pair(dir,ds):\n",
    "    fn1 = filename_prefix_mapping['active']+ds+filename_suffix_mapping['active']+'.csv'\n",
    "    fn2 = filename_prefix_mapping['reactive']+ds+filename_suffix_mapping['reactive']+'.csv'\n",
    "    ffn1 = join(dir,fn1)\n",
    "    ffn2 = join(dir,fn2)\n",
    "    #print(fn1 +' <-> '+ fn2)\n",
    "    return pd.read_csv(ffn1,names=[TIMESTAMP_COLUMN_NAME,ACTIVE_COLUMN_NAME]),pd.read_csv(ffn2,names=[TIMESTAMP_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "\n",
    "def _tidy_data(df):\n",
    "    df.drop_duplicates(subset=[\"timestamp\"], inplace=True) # remove duplicate rows with same timestamp\n",
    "    df.index = pd.to_datetime(df.timestamp.values, unit='s', utc=True) # convert the index to time based\n",
    "    df = df.tz_convert(TIMEZONE) #deal with summertime etc. for London timezone\n",
    "    df = df.drop(TIMESTAMP_COLUMN_NAME, 1) # remove the now redundant timestamp column\n",
    "    df.rename(columns=lambda x: column_mapping[x], inplace=True) #replace column lables with [P,T] pair\n",
    "    df.columns.set_names(LEVEL_NAMES, inplace=True) # rename the columns with 2 levels of name\n",
    "    df = df.convert_objects(convert_numeric=True) # make sure everything is numeric\n",
    "    df = df.dropna() # drop rows with empty cells\n",
    "    df = df.astype(np.float32) #make everything floating point\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "convert_gjw('c:/Users/GJWood/nilm_gjw_data', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
