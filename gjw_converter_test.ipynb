{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening datastore /Users/GJWood/nilm_gjw_data\\HDF5\\nilm_gjw_data.hdf5\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\hooks\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\info\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\heads\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\remotes\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\logs\\refs\\remotes\\origin\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\03\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\07\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\08\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\0d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\16\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\17\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\19\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\1f\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\25\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\2f\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\3b\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\46\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\48\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\4a\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\4d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5b\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5c\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\5d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\60\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\65\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\6d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\6e\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\70\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\71\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\73\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\76\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\79\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\7d\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\7e\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\80\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\88\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\89\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\8f\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\97\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\99\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\a0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\a5\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\ae\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\b2\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\b9\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\bd\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\c0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\c4\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\ca\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\cb\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\cd\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\d9\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e3\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e5\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\e6\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\eb\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f0\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f4\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f6\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\f7\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\info\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\objects\\pack\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\heads\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\remotes\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\remotes\\origin\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.git\\refs\\tags\n",
      "Skipping  c:\\Users\\GJWood\\nilm_gjw_data\\.ipynb_checkpoints\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\\building1\n",
      "checking c:\\Users\\GJWood\\nilm_gjw_data\\building1\\elec\n",
      "found files for date: 2013-11-20\n",
      "found files for date: 2013-11-28\n",
      "found files for date: 2013-12-01\n",
      "found files for date: 2013-12-04\n",
      "found files for date: 2013-12-13\n",
      "found files for date: 2013-12-27\n",
      "found files for date: 2014-01-09\n",
      "found files for date: 2014-02-09\n",
      "found files for date: 2014-03-27\n",
      "found files for date: 2014-05-26\n",
      "found files for date: 2015-05-12\n",
      "found files for date: 2015-05-27\n",
      "csv data written to:  c:\\Users\\GJWood\\nilm_gjw_data\\building1\\elec\\building1_meter1.data\n",
      "Done converting YAML metadata to HDF5!\n",
      "Done converting gjw to HDF5!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from os.path import join, isdir, isfile\n",
    "from os import listdir\n",
    "import fnmatch\n",
    "import re\n",
    "from sys import stdout\n",
    "from nilmtk.utils import get_datastore\n",
    "from nilmtk.datastore import Key\n",
    "from nilmtk.timeframe import TimeFrame\n",
    "from nilmtk.measurement import LEVEL_NAMES\n",
    "from nilmtk.utils import get_module_directory, check_directory_exists\n",
    "from nilm_metadata import convert_yaml_to_hdf5, save_yaml_to_datastore\n",
    "\n",
    "column_mapping = {\n",
    "    'active': ('power', 'active'),\n",
    "    'reactive': ('power', 'reactive')\n",
    "    \n",
    "}\n",
    "# data for file name manipulation\n",
    "filename_prefix_mapping = {\n",
    "    'active' : ('4-POWER_REAL_FINE '),\n",
    "    'reactive' : ('5-POWER_REACTIVE_STANDARD ')\n",
    "}\n",
    "filename_suffix_mapping = {\n",
    "    'active' : (' Dump'),\n",
    "    'reactive' : (' Dump')\n",
    "}\n",
    "# DataFrame column names\n",
    "TIMESTAMP_COLUMN_NAME = \"timestamp\"\n",
    "ACTIVE_COLUMN_NAME = \"active\"\n",
    "REACTIVE_COLUMN_NAME = \"reactive\"\n",
    "\n",
    "TIMEZONE = \"Europe/London\" # local time zone\n",
    "home_dir='/Users/GJWood/nilm_gjw_data' # path to input data\n",
    "\n",
    "#regular expression matching\n",
    "bld_re = re.compile('building\\d+') #used to pull building name from directory path\n",
    "bld_nbr_re = re.compile ('\\d+') # used to pull the building number from the name\n",
    "iso_date_re = re.compile ('\\d{4}-\\d{2}-\\d{2}') # used to pull the date from the file name\n",
    "\n",
    "def convert_gjw(gjw_path, output_filename, format=\"HDF\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    gjw_path : str\n",
    "        The root path of the gjw dataset.\n",
    "    output_filename : str\n",
    "        The destination filename (including path and suffix), will default if not specified\n",
    "    directory and file structure\n",
    "    nilm_gjw_data\n",
    "        building<1>\n",
    "            elec\n",
    "                4-POWER_REAL_FINE <date> Dump.csv\n",
    "                5-POWER_REACTIVE_STANDARD <date> Dump.csv\n",
    "                ...\n",
    "        ...\n",
    "        building<n>\n",
    "        HDF5\n",
    "            nilm_gjw_data.hdf5\n",
    "        metadata\n",
    "            building1.yaml\n",
    "            dataset.yaml\n",
    "            meter_devices.yaml\n",
    "        other files    \n",
    "    \"\"\"\n",
    "    if gjw_path is None: gjwpath = home_dir\n",
    "    check_directory_exists(gjw_path)\n",
    "    os.chdir(gjw_path)\n",
    "    gjw_path = os.getcwd()  # sort out potential issue with slashes or backslashes\n",
    "    if output_filename is None:\n",
    "        output_filename =join(home_dir,'HDF5','nilm_gjw_data.hdf5')\n",
    "    elec_path = join(gjw_path, 'building1','elec')\n",
    "    # Open data store\n",
    "    print( 'opening datastore', output_filename)\n",
    "    store = get_datastore(output_filename, format, mode='w')\n",
    "    # walk the directory tree from the dataset home directory\n",
    "    #clear dataframe & add column headers\n",
    "    df = pd.DataFrame(columns=[ACTIVE_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "    found = False\n",
    "    for current_dir, dirs_in_current_dir, files in os.walk(gjw_path):\n",
    "        if current_dir.find('.git')!=-1 or current_dir.find('.ipynb') != -1:\n",
    "            print( 'Skipping ', current_dir)\n",
    "            continue\n",
    "        print( 'checking', current_dir)\n",
    "        m = bld_re.search(current_dir)\n",
    "        if m: #The csv files may be further down the tree so this section may be repeated\n",
    "            building_name = m.group()\n",
    "            building_nbr = int(bld_nbr_re.search(building_name).group())\n",
    "            meter_nbr = 1\n",
    "            key = Key(building=building_nbr, meter=meter_nbr)\n",
    "        for items in fnmatch.filter(files, \"4*.csv\"):\n",
    "            # process any .CSV files found\n",
    "            found = True\n",
    "            ds = iso_date_re.search(items).group()\n",
    "            print( 'found files for date:', ds)\n",
    "            # found files to process\n",
    "            df1 = _read_file_pair(current_dir,ds) # read two csv files into a dataframe    \n",
    "            # resample on single file only as there may be gaps between dumps            \n",
    "            df2 = df1.resample('S',fill_method='ffill') # make sure we have a reading for every second \n",
    "            df = pd.concat([df,df2]) # concatenate the results into one long dataframe\n",
    "        if found:\n",
    "            found = False\n",
    "            df = _prepare_data_for_toolkit(df)\n",
    "            csvout_fn ='building'+str(building_nbr)+'_meter'+str(meter_nbr)+'.data'\n",
    "            csvout_ffn = join(current_dir,csvout_fn) # not called .csv to avoid clash\n",
    "            df.to_csv(csvout_ffn)\n",
    "            print(\"csv data written to: \", csvout_ffn)\n",
    "            store.put(str(key), df)\n",
    "            #clear dataframe & add column headers\n",
    "            #df = pd.DataFrame(columns=[ACTIVE_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "            break # only 1 folder with .csv files at present\n",
    "    store.close()\n",
    "    convert_yaml_to_hdf5(join(gjw_path, 'metadata'),output_filename)\n",
    "    print(\"Done converting gjw to HDF5!\")\n",
    "\n",
    "def _read_file_pair(dir,ds):\n",
    "    \"\"\"\"\n",
    "    parameters \n",
    "        dir - the directory path where the files may be found\n",
    "        ds  - the date string which identifies the pair of files\n",
    "    The filenames are constructed using the appropriate prefixes and suffixes\n",
    "    The data is then read, merged, de-duplicated, converted to the correct time zone\n",
    "    and converted to a time series\n",
    "    \"\"\"\n",
    "    fn1 = filename_prefix_mapping['active']+ds+filename_suffix_mapping['active']+'.csv'\n",
    "    fn2 = filename_prefix_mapping['reactive']+ds+filename_suffix_mapping['reactive']+'.csv'\n",
    "    ffn1 = join(dir,fn1)\n",
    "    ffn2 = join(dir,fn2)\n",
    "    #print(fn1 +' <-> '+ fn2)\n",
    "    df1 = pd.read_csv(ffn1,names=[TIMESTAMP_COLUMN_NAME,ACTIVE_COLUMN_NAME])\n",
    "    df2 = pd.read_csv(ffn2,names=[TIMESTAMP_COLUMN_NAME,REACTIVE_COLUMN_NAME])\n",
    "    df3 = pd.merge(df1,df2,on=TIMESTAMP_COLUMN_NAME) #merge the two column types into 1 frame\n",
    "    df3.drop_duplicates(subset=[\"timestamp\"], inplace=True) # remove duplicate rows with same timestamp    df3.index = pd.to_datetime(df3.timestamp.values, unit='s', utc=True) # convert the index to time based\n",
    "    df3.index = pd.to_datetime(df3.timestamp.values, unit='s', utc=True) # convert the index to time based\n",
    "    df3 = df3.tz_convert(TIMEZONE) #deal with summertime etc. for London timezone\n",
    "    df3 = df3.drop(TIMESTAMP_COLUMN_NAME, 1) # remove the now redundant timestamp column\n",
    "    return df3\n",
    "    \n",
    "def _prepare_data_for_toolkit(df):\n",
    "    #remove any duplicate timestamps between files\n",
    "    df[\"timestamp\"] = df.index # add the index back in as a column \n",
    "    df.drop_duplicates(subset=[\"timestamp\"], inplace=True) # remove duplicate rows with same timestamp\n",
    "    df = df.drop(\"timestamp\",1) # remove the timestamp column  \n",
    "    df.rename(columns=lambda x: column_mapping[x], inplace=True) # Renaming from gjw header to nilmtk controlled vocabulary\n",
    "    df.columns.set_names(LEVEL_NAMES, inplace=True) # Needed for column levelling (all converter need this line)\n",
    "    df = df.convert_objects(convert_numeric=True) # make sure everything is numeric\n",
    "    df = df.dropna() # drop rows with empty cells\n",
    "    df = df.astype(np.float32) # Change float 64 (default) to float 32 \n",
    "    df = df.sort_index() # Ensure that time series index is sorted\n",
    "    return df\n",
    "    \n",
    "def main():\n",
    "    convert_gjw('c:/Users/GJWood/nilm_gjw_data', None)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
